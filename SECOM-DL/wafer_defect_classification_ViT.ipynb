{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca81939",
   "metadata": {},
   "source": [
    "# Wafer Defect Classification using Vision Transformer (ViT)\n",
    "\n",
    "This notebook implements wafer defect classification using pretrained Vision Transformer models.\n",
    "We'll use the `timm` library for access to state-of-the-art pretrained ViT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b84476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: timm in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (1.0.21)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (0.15.0)\n",
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: torch in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (from timm) (2.0.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\programdata\\anaconda3\\lib\\site-packages (from timm) (0.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch->timm) (2.8.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (from torch->timm) (4.13.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch->timm) (3.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch->timm) (3.1.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch->timm) (2.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch->timm) (1.2.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchsummary in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (1.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (1.6.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\cl502_14\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install timm torchvision transformers\n",
    "!pip install torchsummary scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe543f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cpu\n",
      "TIMM version: 1.0.21\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split, SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Transformer and model imports\n",
    "import timm\n",
    "from torchsummary import summary\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TIMM version: {timm.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e07907",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "Using the same data preprocessing pipeline as the original notebook but adapted for Vision Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33769c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (811457, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 811457 entries, 0 to 811456\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   dieSize         811457 non-null  float64\n",
      " 1   failureType     811457 non-null  object \n",
      " 2   lotName         811457 non-null  object \n",
      " 3   trainTestLabel  811457 non-null  object \n",
      " 4   waferIndex      811457 non-null  float64\n",
      " 5   waferMap        811457 non-null  object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 37.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_pickle(\"MIR-WM811K/Python/WM811K.pkl\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f512d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset shape: (811457, 7)\n",
      "\n",
      "Failure type distribution:\n",
      "0 0          638507\n",
      "none         147431\n",
      "Edge-Ring      9680\n",
      "Edge-Loc       5189\n",
      "Center         4294\n",
      "Loc            3593\n",
      "Scratch        1193\n",
      "Random          866\n",
      "Donut           555\n",
      "Near-full       149\n",
      "Name: failureType, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing - same as original but optimized\n",
    "def preprocess_data(df):\n",
    "    # Drop waferIndex column\n",
    "    df = df.drop(['waferIndex'], axis=1)\n",
    "    \n",
    "    # Add waferMapDim column\n",
    "    def find_dim(x):\n",
    "        dim0 = np.size(x, axis=0)\n",
    "        dim1 = np.size(x, axis=1)\n",
    "        return dim0, dim1\n",
    "    \n",
    "    df['waferMapDim'] = df.waferMap.apply(find_dim)\n",
    "    \n",
    "    # Clean failure types\n",
    "    df['failureType'] = df['failureType'].astype(str).str.replace(r\"[\\[\\]']\", \"\", regex=True)\n",
    "    \n",
    "    # Mapping failure types to numbers\n",
    "    mapping_type = {\n",
    "        'Center': 0, 'Donut': 1, 'Edge-Loc': 2, 'Edge-Ring': 3,\n",
    "        'Loc': 4, 'Random': 5, 'Scratch': 6, 'Near-full': 7, 'none': 8\n",
    "    }\n",
    "    df['failureNum'] = df['failureType'].map(mapping_type)\n",
    "    \n",
    "    # Filter labeled data\n",
    "    df_withlabel = df[df['failureType'] != 0].reset_index(drop=True)\n",
    "    \n",
    "    return df_withlabel\n",
    "\n",
    "df_processed = preprocess_data(df)\n",
    "print(f\"Processed dataset shape: {df_processed.shape}\")\n",
    "print(\"\\nFailure type distribution:\")\n",
    "print(df_processed['failureType'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ce723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing wafer maps...\n",
      "Processed 0/811457 samples\n",
      "Processed 10000/811457 samples\n",
      "Processed 20000/811457 samples\n",
      "Processed 30000/811457 samples\n",
      "Processed 40000/811457 samples\n",
      "Processed 50000/811457 samples\n",
      "Processed 60000/811457 samples\n",
      "Processed 70000/811457 samples\n",
      "Processed 80000/811457 samples\n",
      "Processed 90000/811457 samples\n",
      "Processed 100000/811457 samples\n",
      "Processed 110000/811457 samples\n",
      "Processed 120000/811457 samples\n",
      "Processed 130000/811457 samples\n",
      "Processed 140000/811457 samples\n",
      "Processed 150000/811457 samples\n",
      "Processed 160000/811457 samples\n",
      "Processed 170000/811457 samples\n",
      "Processed 180000/811457 samples\n",
      "Processed 190000/811457 samples\n",
      "Processed 200000/811457 samples\n",
      "Processed 210000/811457 samples\n"
     ]
    }
   ],
   "source": [
    "# Extract and prepare wafer maps for ViT\n",
    "def prepare_wafer_data_for_vit(df_withlabel, target_size=224):\n",
    "    \"\"\"\n",
    "    Prepare wafer map data for Vision Transformer\n",
    "    ViT typically works with 224x224 RGB images\n",
    "    \"\"\"\n",
    "    wafer_maps = []\n",
    "    labels = []\n",
    "    \n",
    "    print(\"Processing wafer maps...\")\n",
    "    for idx, row in df_withlabel.iterrows():\n",
    "        if idx % 10000 == 0:\n",
    "            print(f\"Processed {idx}/{len(df_withlabel)} samples\")\n",
    "            \n",
    "        wafer_map = row['waferMap']\n",
    "        failure_type = row['failureType']\n",
    "        \n",
    "        # Convert to RGB (0: non-wafer -> R, 1: normal -> G, 2: defect -> B)\n",
    "        h, w = wafer_map.shape\n",
    "        rgb_map = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        \n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                pixel_val = int(wafer_map[i, j])\n",
    "                if pixel_val < 3:  # Ensure valid pixel values\n",
    "                    rgb_map[i, j, pixel_val] = 255\n",
    "        \n",
    "        # Resize to target size for ViT\n",
    "        pil_image = Image.fromarray(rgb_map)\n",
    "        resized_image = pil_image.resize((target_size, target_size), Image.LANCZOS)\n",
    "        resized_array = np.array(resized_image)\n",
    "        \n",
    "        wafer_maps.append(resized_array)\n",
    "        labels.append(failure_type)\n",
    "    \n",
    "    return np.array(wafer_maps), np.array(labels)\n",
    "\n",
    "# Prepare data\n",
    "wafer_images, wafer_labels = prepare_wafer_data_for_vit(df_processed)\n",
    "print(f\"\\nWafer images shape: {wafer_images.shape}\")\n",
    "print(f\"Wafer labels shape: {wafer_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ee2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample wafer maps\n",
    "plt.figure(figsize=(15, 10))\n",
    "failure_types = np.unique(wafer_labels)\n",
    "for i, failure_type in enumerate(failure_types[:9]):\n",
    "    idx = np.where(wafer_labels == failure_type)[0][0]\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(wafer_images[idx])\n",
    "    plt.title(f'Failure Type: {failure_type}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc85281",
   "metadata": {},
   "source": [
    "## Vision Transformer Data Transforms\n",
    "Define proper data augmentation and normalization for ViT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63adafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for ViT\n",
    "class ViTDataTransforms:\n",
    "    def __init__(self, img_size=224):\n",
    "        # ImageNet normalization (standard for pretrained models)\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self.val_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "# Custom Dataset class\n",
    "class WaferDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None, label_encoder=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.label_encoder = label_encoder\n",
    "        \n",
    "        # Encode labels to integers\n",
    "        if label_encoder is None:\n",
    "            unique_labels = np.unique(labels)\n",
    "            self.label_encoder = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        else:\n",
    "            self.label_encoder = label_encoder\n",
    "            \n",
    "        self.encoded_labels = [self.label_encoder[label] for label in labels]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.encoded_labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "transforms_vit = ViTDataTransforms()\n",
    "print(\"ViT transforms created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a13759",
   "metadata": {},
   "source": [
    "## Vision Transformer Model Definition\n",
    "Using pretrained ViT models from `timm` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaferViTClassifier(nn.Module):\n",
    "    def __init__(self, model_name='vit_base_patch16_224', num_classes=9, pretrained=True):\n",
    "        super(WaferViTClassifier, self).__init__()\n",
    "        \n",
    "        # Load pretrained ViT model\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        \n",
    "        # Get the number of features from the classifier\n",
    "        if hasattr(self.backbone, 'head'):\n",
    "            num_features = self.backbone.head.in_features\n",
    "            # Replace the head with our custom classifier\n",
    "            self.backbone.head = nn.Identity()\n",
    "        elif hasattr(self.backbone, 'classifier'):\n",
    "            num_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        else:\n",
    "            # Fallback - assume 768 for base ViT\n",
    "            num_features = 768\n",
    "        \n",
    "        # Custom classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get features from backbone\n",
    "        features = self.backbone(x)\n",
    "        # Classify\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "# Available ViT models to try\n",
    "available_models = [\n",
    "    'vit_tiny_patch16_224',\n",
    "    'vit_small_patch16_224', \n",
    "    'vit_base_patch16_224',\n",
    "    'vit_base_patch16_384',\n",
    "    'vit_large_patch16_224'\n",
    "]\n",
    "\n",
    "print(\"Available ViT models:\")\n",
    "for i, model in enumerate(available_models):\n",
    "    print(f\"{i+1}. {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c93d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device and model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model - starting with base ViT\n",
    "model_name = 'vit_base_patch16_224'\n",
    "num_classes = len(np.unique(wafer_labels))\n",
    "\n",
    "model = WaferViTClassifier(model_name=model_name, num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"\\nCreated {model_name} with {num_classes} output classes\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96781d",
   "metadata": {},
   "source": [
    "## Data Preparation and Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "dataset = WaferDataset(wafer_images, wafer_labels, transform=transforms_vit.train_transform)\n",
    "print(f\"Dataset created with {len(dataset)} samples\")\n",
    "print(f\"Label encoder: {dataset.label_encoder}\")\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 3e-5,  # Lower LR for fine-tuning\n",
    "    'num_epochs': 15,\n",
    "    'weight_decay': 1e-4,\n",
    "    'num_folds': 5\n",
    "}\n",
    "\n",
    "print(f\"Training configuration: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eadef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation functions\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc, all_predictions, all_labels\n",
    "\n",
    "print(\"Training functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e899481",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca4df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=config['num_folds'], shuffle=True, random_state=42)\n",
    "fold_results = {}\n",
    "best_models = {}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(range(len(dataset)))):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{config['num_folds']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create data loaders for this fold\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=config['batch_size'], \n",
    "                             sampler=train_sampler, num_workers=2)\n",
    "    val_loader = DataLoader(dataset, batch_size=config['batch_size'], \n",
    "                           sampler=val_sampler, num_workers=2)\n",
    "    \n",
    "    # Create fresh model for this fold\n",
    "    fold_model = WaferViTClassifier(model_name=model_name, num_classes=num_classes)\n",
    "    fold_model = fold_model.to(device)\n",
    "    \n",
    "    # Setup optimizer and criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(fold_model.parameters(), \n",
    "                           lr=config['learning_rate'], \n",
    "                           weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, config['num_epochs'])\n",
    "    \n",
    "    # Training history for this fold\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config['num_epochs']}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(fold_model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, val_predictions, val_labels = validate_epoch(\n",
    "            fold_model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_models[fold] = {\n",
    "                'model_state': fold_model.state_dict().copy(),\n",
    "                'val_acc': val_acc,\n",
    "                'predictions': val_predictions,\n",
    "                'labels': val_labels\n",
    "            }\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Store fold results\n",
    "    fold_results[fold] = history\n",
    "    print(f\"\\nFold {fold+1} Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CROSS VALIDATION COMPLETED\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780d42a4",
   "metadata": {},
   "source": [
    "## Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e15cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall performance metrics\n",
    "fold_train_accs = []\n",
    "fold_val_accs = []\n",
    "fold_train_losses = []\n",
    "fold_val_losses = []\n",
    "\n",
    "for fold in range(config['num_folds']):\n",
    "    history = fold_results[fold]\n",
    "    fold_train_accs.append(max(history['train_acc']))\n",
    "    fold_val_accs.append(max(history['val_acc']))\n",
    "    fold_train_losses.append(min(history['train_loss']))\n",
    "    fold_val_losses.append(min(history['val_loss']))\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Vision Transformer (ViT) Performance Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Average Training Accuracy: {np.mean(fold_train_accs):.4f} ± {np.std(fold_train_accs):.4f}\")\n",
    "print(f\"Average Validation Accuracy: {np.mean(fold_val_accs):.4f} ± {np.std(fold_val_accs):.4f}\")\n",
    "print(f\"Average Training Loss: {np.mean(fold_train_losses):.4f} ± {np.std(fold_train_losses):.4f}\")\n",
    "print(f\"Average Validation Loss: {np.mean(fold_val_losses):.4f} ± {np.std(fold_val_losses):.4f}\")\n",
    "print(f\"Best Validation Accuracy: {max(fold_val_accs):.4f}\")\n",
    "\n",
    "# Store results for comparison\n",
    "vit_results = {\n",
    "    'model_name': 'Vision Transformer (ViT)',\n",
    "    'avg_train_acc': np.mean(fold_train_accs),\n",
    "    'avg_val_acc': np.mean(fold_val_accs),\n",
    "    'std_train_acc': np.std(fold_train_accs),\n",
    "    'std_val_acc': np.std(fold_val_accs),\n",
    "    'avg_train_loss': np.mean(fold_train_losses),\n",
    "    'avg_val_loss': np.mean(fold_val_losses),\n",
    "    'best_val_acc': max(fold_val_accs),\n",
    "    'fold_results': fold_results,\n",
    "    'config': config\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab36c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot training curves for each fold\n",
    "for fold in range(config['num_folds']):\n",
    "    history = fold_results[fold]\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Training and validation loss\n",
    "    axes[0, 0].plot(epochs, history['train_loss'], label=f'Fold {fold+1}')\n",
    "    axes[0, 1].plot(epochs, history['val_loss'], label=f'Fold {fold+1}')\n",
    "    \n",
    "    # Training and validation accuracy\n",
    "    axes[1, 0].plot(epochs, history['train_acc'], label=f'Fold {fold+1}')\n",
    "    axes[1, 1].plot(epochs, history['val_acc'], label=f'Fold {fold+1}')\n",
    "\n",
    "axes[0, 0].set_title('Training Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "axes[0, 1].set_title('Validation Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "axes[1, 0].set_title('Training Accuracy')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "axes[1, 1].set_title('Validation Accuracy')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56266733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for best performing fold\n",
    "best_fold = max(best_models.keys(), key=lambda k: best_models[k]['val_acc'])\n",
    "best_predictions = best_models[best_fold]['predictions']\n",
    "best_labels = best_models[best_fold]['labels']\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(best_labels, best_predictions)\n",
    "label_names = list(dataset.label_encoder.keys())\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_names, yticklabels=label_names)\n",
    "plt.title(f'Confusion Matrix - ViT (Best Fold: {best_fold+1})')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nClassification Report - Best Fold ({best_fold+1}):\")\n",
    "print(classification_report(best_labels, best_predictions, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results and best model\n",
    "import pickle\n",
    "\n",
    "# Save ViT results\n",
    "with open('vit_wafer_classification_results.pkl', 'wb') as f:\n",
    "    pickle.dump(vit_results, f)\n",
    "\n",
    "# Save best model\n",
    "best_model_path = 'best_vit_wafer_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': best_models[best_fold]['model_state'],\n",
    "    'model_name': model_name,\n",
    "    'num_classes': num_classes,\n",
    "    'label_encoder': dataset.label_encoder,\n",
    "    'config': config,\n",
    "    'val_accuracy': best_models[best_fold]['val_acc']\n",
    "}, best_model_path)\n",
    "\n",
    "print(f\"Results saved to: vit_wafer_classification_results.pkl\")\n",
    "print(f\"Best model saved to: {best_model_path}\")\n",
    "print(f\"Best validation accuracy: {best_models[best_fold]['val_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ecf66",
   "metadata": {},
   "source": [
    "## Model Interpretation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b66dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for analysis\n",
    "analysis_model = WaferViTClassifier(model_name=model_name, num_classes=num_classes)\n",
    "analysis_model.load_state_dict(best_models[best_fold]['model_state'])\n",
    "analysis_model = analysis_model.to(device)\n",
    "analysis_model.eval()\n",
    "\n",
    "# Feature analysis function\n",
    "def analyze_predictions(model, dataset, device, num_samples=10):\n",
    "    model.eval()\n",
    "    \n",
    "    # Get some random samples\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            image, true_label = dataset[idx]\n",
    "            image_batch = image.unsqueeze(0).to(device)\n",
    "            \n",
    "            # Get prediction\n",
    "            outputs = model(image_batch)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "            confidence = probabilities[0, predicted_class].item()\n",
    "            \n",
    "            # Convert back to label names\n",
    "            label_names = list(dataset.label_encoder.keys())\n",
    "            true_label_name = label_names[true_label]\n",
    "            pred_label_name = label_names[predicted_class]\n",
    "            \n",
    "            # Display original image (denormalize for visualization)\n",
    "            img_display = image.clone()\n",
    "            # Denormalize\n",
    "            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "            img_display = img_display * std + mean\n",
    "            img_display = torch.clamp(img_display, 0, 1)\n",
    "            \n",
    "            axes[i].imshow(img_display.permute(1, 2, 0))\n",
    "            axes[i].set_title(f'True: {true_label_name}\\nPred: {pred_label_name}\\nConf: {confidence:.3f}',\n",
    "                             color='green' if true_label == predicted_class else 'red')\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('ViT Prediction Analysis', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_predictions(analysis_model, dataset, device)\n",
    "print(\"Prediction analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc24b20",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook implemented Vision Transformer (ViT) for wafer defect classification with the following key features:\n",
    "\n",
    "1. **Pretrained ViT Model**: Used `timm` library for state-of-the-art pretrained transformers\n",
    "2. **Proper Data Preprocessing**: Adapted wafer maps to RGB format suitable for ViT\n",
    "3. **Data Augmentation**: Applied appropriate transforms for better generalization\n",
    "4. **K-Fold Cross Validation**: Robust evaluation methodology\n",
    "5. **Comprehensive Analysis**: Training curves, confusion matrices, and prediction analysis\n",
    "\n",
    "### Key Advantages of ViT:\n",
    "- **Global Context**: Attention mechanism captures long-range dependencies\n",
    "- **Transfer Learning**: Benefits from large-scale pretraining\n",
    "- **Scalability**: Performs better with larger datasets\n",
    "- **Interpretability**: Attention maps can provide insights\n",
    "\n",
    "### Next Steps:\n",
    "1. Create Swin Transformer implementation\n",
    "2. Develop comparative analysis framework\n",
    "3. Implement wafer life expectancy prediction\n",
    "4. Optimize hyperparameters and model architectures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
